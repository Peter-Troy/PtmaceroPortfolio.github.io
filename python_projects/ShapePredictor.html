<!DOCTYPE HTML>
<!--
	Phantom by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Peter Troy C. Macero</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="../assets/css/main.css" />

		<noscript><link rel="stylesheet" href="../assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">
		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<div class="inner">

							<!-- Logo -->
							<a href="../index.html" class="logo">
								<span class="symbol"><img src="../images/profilepic.png" alt="" /></span><span class="title">Peter Troy C. Macero</span>
							</a>
              
							<!-- Nav -->
								<nav>
									<ul>
										<li><a href="#menu">Menu</a></li>
									</ul>
								</nav>
						</div>
					</header>

				<!-- Menu -->
					<nav id="menu">
						<h2>Menu</h2>
						<ul>
							<li><a href="../index.html">Home</a></li>
              <li><a href="../javascript_projects/javascript_projects.html">Javascript Projects</a></li>
							<li><a href="../python_projects/python_projects.html">Python Projects</a></li>
							<li><a href="../crud_projects/crud_projects.html">CRUD Projects</a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">
						<div class="inner">
							<div style="text-align: center;">	
								<h1><a>Simple Shape Predictor</a></h1>
							</div>
							<p>The Simple Shape Predictor lets users draw shapes like crosses, squares, and triangles on a canvas. It then guesses the shape using a trained AI model. The app is made with Python, Tkinter, PyTorch, and other tools, creating a fun and interactive way to draw and recognize shapes.
                            </p>
              <div style="text-align: center;">	
                <h1><a>How to train the model?</a></h1>
                <p>The app lets users draw shapes (limited to Square, Triangle, and Cross) using a mouse on a Tkinter canvas. After drawing, it processes the image and uses a trained AI model to guess the shape. It can recognize crosses, squares, and triangles. The interface is simple, with buttons to clear the canvas and predict the shape.</p>
                <p>Added a random 500 auto generated shapes to enhance Accuracy</p>
                    <div class="row" style="content: ''; clear: both; display: table;">
                      <div class="column" style="float: left; width: 33.33%; padding: 5px;">
                          <img src="ShapePredictor_image/500cross.png" alt="Snow" style="width:100%; height:auto; border-radius:10px; box-shadow:0px 4px 8px rgba(0, 0, 0, 0.2);">
                      </div>
                      <div class="column" style="float: left; width: 33.33%; padding: 5px;">
                          <img src="ShapePredictor_image/500triangle.png" alt="Forest" style="width:100%; height:auto; border-radius:10px; box-shadow:0px 4px 8px rgba(0, 0, 0, 0.2);">
                      </div>
                      <div class="column" style="float: left; width: 33.33%; padding: 5px;">
                          <img src="ShapePredictor_image/500square.png" alt="Mountains" style="width:100%; height:auto; border-radius:10px; box-shadow:0px 4px 8px rgba(0, 0, 0, 0.2);">
                      </div>
                    </div>
              </div>

             

  
              <h2><a>Model Quality Testing: Evaluating Shape Recognition Accuracy - CROSS</a></h2>
                            <video width="640" height="360" controls>
                            <source src="ShapePredictor_image/cross.mp4" type="video/mp4">
                            </video>
                            <p>test 1 - Success</p>
                            <span class="image "><img src="ShapePredictor_image/cross/cross1.png"  width="700" height="450" alt="" /></span>
                            <p>test 2 - Success</p>
                            <span class="image "><img src="ShapePredictor_image/cross/cross2.png"  width="700" height="450" alt="" /></span>
                            <p>test 3 - Success</p>
                            <span class="image "><img src="ShapePredictor_image/cross/cross3.png"  width="700" height="450" alt="" /></span>
                            <p>test 4 - Fail. Model only recognize shapes mostly in the center and reads the cross as a square instead.</p>
                            <span class="image "><img src="ShapePredictor_image/cross/cross4.png"  width="700" height="450" alt="" /></span>
                            <p>test 5 - Fail. Model only recognize shapes mostly in the center and reads the cross as a square instead.</p>
                            <span class="image "><img src="ShapePredictor_image/cross/cross5.png"  width="700" height="450" alt="" /></span>
                            <p>test 6 - Success</p>
                            <span class="image "><img src="ShapePredictor_image/cross/cross6.png"  width="700" height="450" alt="" /></span>
                            <p>test 7 - Success</p>
                            <span class="image "><img src="ShapePredictor_image/cross/cross7.png"  width="700" height="450" alt="" /></span>
                            <p>test 8 - Success</p>
                            <span class="image "><img src="ShapePredictor_image/cross/cross8.png"  width="700" height="450" alt="" /></span>
                            <p>test 9 - Success</p>
                            <span class="image "><img src="ShapePredictor_image/cross/cross9.png"  width="700" height="450" alt="" /></span>
                            <p>test 10 - Success</p>
                            <span class="image "><img src="ShapePredictor_image/cross/cross10.png"  width="700" height="450" alt="" /></span>
                            <p>Conclusion: The model correctly identified the shapes 8 out of 10 times during testing, indicating that it performs well overall. However, the misclassification of the cross as a square on both the left and right sides suggests that the model may have some difficulty with shapes drawn off-center. This could be due to training data bias or positioning issues, and further adjustments to the training process or preprocessing steps may help improve accuracy in such cases.</p>
                
                            <h2><a>Model Quality Testing: Evaluating Shape Recognition Accuracy - TRIANGLE</a></h2>
                            <video width="640" height="360" controls>
                            <source src="ShapePredictor_image/triangle.mp4" type="video/mp4">
                            </video>
                            <p>test 1 - Success</p>
                            <span class="image "><img src="ShapePredictor_image/triangle/triangle1.png"  width="700" height="450" alt="" /></span>
                            <p>test 2 - Success</p>
                            <span class="image "><img src="ShapePredictor_image/triangle/triangle2.png"  width="700" height="450" alt="" /></span>
                            <p>test 3 - Fail. Model only recognize shapes mostly in the center and reads the triangle as a square instead.</p>
                            <span class="image "><img src="ShapePredictor_image/triangle/triangle3.png"  width="700" height="450" alt="" /></span>
                            <p>test 4 - Fail. Model only recognize shapes mostly in the center and reads the triangle as a square instead.</p>
                            <span class="image "><img src="ShapePredictor_image/triangle/triangle4.png"  width="700" height="450" alt="" /></span>
                            <p>test 5 - Success</p>
                            <span class="image "><img src="ShapePredictor_image/triangle/triangle5.png"  width="700" height="450" alt="" /></span>
                            <p>test 6 - Success</p>
                            <span class="image "><img src="ShapePredictor_image/triangle/triangle6.png" width="700" height="450" alt="" /></span>
                            <p>test 7 - Fail. Model only recognize shapes mostly in the center and reads the triangle as a square instead.</p>
                            <span class="image "><img src="ShapePredictor_image/triangle/triangle7.png" width="700" height="450" alt="" /></span>
                            <p>test 8 - Fail. Drew a right triangle, but reads it as square.</p>
                            <span class="image "><img src="ShapePredictor_image/triangle/triangle8.png"  width="700" height="450" alt="" /></span>
                            <p>test 9 - Success</p>
                            <span class="image "><img src="ShapePredictor_image/triangle/triangle9.png"  width="700" height="450" alt="" /></span>
                            <p>test 10 - Success</p>
                            <span class="image "><img src="ShapePredictor_image/triangle/triangle10.png"  width="700" height="450" alt="" /></span>
                            <p>Conclusion: The model correctly identified the triangle 6 out of 10 times, but it misclassified it as a square when drawn on the left and right sides of the canvas, as well as when drawn as a right triangle. This suggests that the model struggles with shapes drawn off-center or in different orientations. Further improvements in training and data diversity may help address these issues.</p>

                            <h2><a>Model Quality Testing: Evaluating Shape Recognition Accuracy - SQUARE</a></h2>
                            <video width="640" height="360" controls>
                            <source src="ShapePredictor_image/square.mp4" type="video/mp4">
                            </video>
                            <p>test 1 - Success</p>
                            <span class="image "><img src="ShapePredictor_image/square/square1.png"  width="700" height="450" alt="" /></span>
                            <p>test 2 - Success</p>
                            <span class="image "><img src="ShapePredictor_image/square/square2.png"  width="700" height="450" alt="" /></span>
                            <p>test 3 - Success</p>
                            <span class="image "><img src="ShapePredictor_image/square/square3.png"  width="700" height="450" alt="" /></span>
                            <p>test 4 - Success</p>
                            <span class="image "><img src="ShapePredictor_image/square/square4.png"  width="700" height="450" alt="" /></span>
                            <p>test 5 - Success</p>
                            <span class="image "><img src="ShapePredictor_image/square/square5.png"  width="700" height="450" alt="" /></span>
                            <p>test 6 - Success</p>
                            <span class="image "><img src="ShapePredictor_image/square/square6.png" width="700" height="450" alt="" /></span>
                            <p>test 7 - Success</p>
                            <span class="image "><img src="ShapePredictor_image/square/square7.png" width="700" height="450" alt="" /></span>
                            <p>test 8 - Success</p>
                            <span class="image "><img src="ShapePredictor_image/square/square8.png"  width="700" height="450" alt="" /></span>
                            <p>test 9 - Fail. Drew a shape that looks like a square but has 5 corners, model still reads it as square.</p>
                            <span class="image "><img src="ShapePredictor_image/square/square9.png"  width="700" height="450" alt="" /></span>
                            <p>test 10 - Success</p>
                            <span class="image "><img src="ShapePredictor_image/square/square10.png"  width="700" height="450" alt="" /></span>
                            <p>Conclusion: Correctly predicted the square with a score of 9 out of 10, even when there was a slight deviation (the 5th corner). This shows that the model is quite accurate in recognizing standard shapes, but it still has room for improvement when handling minor variations or imperfections. Overall, the app performs well, but further fine-tuning could enhance its ability to handle shape irregularities more effectively.</p>


                            <div style="text-align: center;">	
                                <h1><a>Challenges during the making of this project</a></h1>
                            </div>

                            <h2><a>Shape Drawing and Size Management:</a></h2>
                            <p> Issue: the shapes drawn on the canvas were too large due to the large size of the lines and the cross.</p>
                            <p>Solution: Resized the lines and reduced their width to make the drawn shapes smaller and more manageable, improving the user experience.</p>
                            
        
                            <h2><a>Image Preprocessing for Prediction:</a></h2>
                            <p> Issue: The app needed to correctly preprocess the user-drawn image to fit the expected format of the trained model.</p>
                            <p>Solution: Used PIL (Python Imaging Library) to resize the drawn image to 64x64 pixels before passing it to the model, ensuring the input matches the model's training requirements</p>
                            
                            
                            <h2><a>Model Training and Accuracy:</a></h2>
                            <p>Issue: the model did not provide accurate predictions for the shapes, possibly due to insufficient training or improper preprocessing.</p>
                            <p>Solution:improved the model by training it with better data and making sure the input images were processed consistently. Adjusted the model's architecture to better suit shape classification.</p>
              

                            <h2><a>Model Integration and Testing:</a></h2>
                            <p>Issue:Integrating the model with the app involved ensuring that the prediction was correctly displayed after the user drew a shape.</p>
                            <p>Solution: successfully loaded the trained model weights into the app and integrated the prediction function, displaying the predicted shape using messagebox.</p>


                            <h2><a>Cross Platform Compatibility:</a></h2>
                            <p>Issue: The app needed to work on different systems, including various operating systems and hardware setups.</p>
                            <p>Solution: To ensure compatibility, I used widely supported libraries like Tkinter, PIL, and Torch, making sure the app runs smoothly across different platforms.</p>
						
                            <h2><a>Shape Drawing Adjustment:</a></h2>
                            <p>Adjusted the size of the lines used to create the shapes (e.g., cross) by changing the parameters in the drawing functions. This allowed the shapes to be drawn at a smaller, more appropriate scale</p>

                            <h2><a>Resizing Images for Model Input:</a></h2>
                            <p>Utilized the PIL library to resize images to 64x64 pixels, which is the required input size for the CNN model. This ensured that the model could process the images correctly.</p>

                            <h2><a>Model Training Process:</a></h2>
                            <p>The model was trained in PyTorch using a CNN with two convolutional layers and fully connected layers. Its weights were saved and loaded into the app for predictions.</p>
                            <p>Convolutional layers are a key part of Convolutional Neural Networks (CNNs). They apply filters to input data (like images) to detect patterns such as edges, textures, or shapes. These layers help the network recognize important features in an image while preserving spatial relationships.</p>

                            <h2><a>Integrating Model with Tkinter App:</a></h2>
                            <p>Used the torch library to load the pre-trained model and used the transform function for image preprocessing. The predict_image function was responsible for feeding the user’s drawing into the model and displaying the prediction.</p>

                            <h2><a>Addressing Prediction Issues:</a></h2>
                            <p>During testing, predictions were inaccurate. This was resolved by adjusting input preprocessing steps, such as normalization and resizing, and improving the training dataset</p>
                            

                            <div style="text-align: center;">	
                              <h1><a>Lessons Learned</a></h1>
                          </div>

                          <h2><a>Importance of Image Preprocessing</a></h2>
                          <p>Learned that proper image preprocessing is crucial for ensuring that the input images fed into the model are in the correct format, both in terms of size and normalization.</p>

                          <h2><a>Fine-Tuning the Model for Specific Tasks</a></h2>
                          <p>Fine-tuning the model for specific shapes (cross, square, triangle) highlighted the importance of the training dataset in achieving high accuracy. More diverse and precise data resulted in better predictions.</p>

                          <h2><a>User Experience Focus</a></h2>
                          <p>Reducing the size of drawn shapes and providing a clearer user interface were important lessons learned in improving user experience and making the app intuitive for users.</p>

                          <h2><a>Model Deployment in Interactive Applications</a></h2>
                          <p>Integrating a trained model into an interactive graphical application (like Tkinter) helped us learn how to use machine learning models within a real-time environment, including handling inputs and displaying outputs.</p>

                          <h2><a>Debugging and Testing</a></h2>
                          <p>During development, there were issues with image resizing, drawing size, and model accuracy. These problems showed the importance of testing each part of the system separately and fixing errors before combining them.</p>

                          <h2><a>Conclusion</a></h2>
                          <p>The Simple Shape Predictor App shows how machine learning can work with a simple interface to create an interactive experience. By solving problems with image processing, model training, and UI design, a working app was built that can recognize shapes drawn by users. This project provided useful lessons on machine learning, image processing, and making easy-to-use applications.</p>

                          <div style="text-align: center;">	
                            <h1><a>Future Features to Implement</a></h1>
                          </div>

                          <ul>
                            <li><p><strong>More Shape Categories</strong> – Add support for additional geometric shapes like circles, pentagons, stars, etc</p></li>
                            <li><p><strong>Handwritten Shape Recognition</strong> – Improve the model to recognize imperfect, hand-drawn shapes</p></li>
                            <li><p><strong>Model Accuracy Enhancements</strong> – Use a deeper CNN model or pre-trained networks (e.g., ResNet, MobileNet)</p></li>
                            <li><p><strong>Real-time Prediction</strong> – Implement real-time shape recognition using OpenCV and a webcam.</p></li>
                            <li><p><strong>Undo/Redo Feature</strong> – Allow users to undo their last strokes on the canvas</p></li>
                            <li><p><strong>Edge Detection for Noise Reduction</strong> – Use techniques like Canny edge detection to improve classification</p></li>
                            <li><p><strong>Dynamic Canvas Size</strong> – Let users resize the drawing canvas for better user experience</p></li>
                            <li><p><strong>Multi-shape Recognition</strong> – Detect multiple shapes drawn on the canvas instead of just one</p></li>
                            <li><p><strong>Save & Load Drawings</strong> – Allow users to save their drawings as images and reload them later</p></li>
                            <li><p><strong>Interactive Feedback</strong> – Show a confidence score and visual hints for incorrect predictions</p></li>
                          </ul>

                          <div style="text-align: center;">	
                            <h1><a>Efficiency Improvements</a></h1>
                          </div>

                          <ul>
                            <li><p><strong>Optimize Model Architecture</strong> – Reduce unnecessary layers or parameters for faster</p></li>
                            <li><p><strong>Batch Prediction Support</strong> – Allow multiple images to be processed in a batch for efficiency</p></li>
                            <li><p><strong>Use TensorRT / ONNX Optimization</strong> – Convert the PyTorch model to ONNX for speed improvements</p></li>
                            <li><p><strong>Reduce Memory Usage</strong> –  Optimize the dataset preprocessing and transformations</p></li>
                            <li><p><strong>Parallel Processing</strong> – Utilize multi-threading for faster image preprocessing and training</p></li>
                            <li><p><strong>Improve Data Augmentation</strong> – Add rotation, scaling, and noise to improve model robustness</p></li>
                          </ul>

                          <div style="text-align: center;">	
                            <h1><a>Project Limitations</a></h1>
                          </div>

                          <ul>
                            <li><p><strong>Limited Dataset</strong> – The model is trained only on a small number of shapes, which may reduce generalization</p></li>
                            <li><p><strong>Grayscale Input Only</strong> – The model only supports grayscale images, making it less flexible</p></li>
                            <li><p><strong>No Complex Shape Detection</strong> – The system cannot recognize overlapping or rotated shapes well</p></li>
                            <li><p><strong>Static Model</strong> – Once trained, the model doesn’t improve unless retrained with new data</p></li>
                            <li><p><strong>Tkinter UI Simplicity</strong> – The Tkinter interface lacks advanced graphical controls compared to frameworks like Streamlit</p></li>
                            <li><p><strong>User-Dependent Accuracy</strong> –  Poorly drawn shapes might lead to incorrect predictions</p></li>
                            <li><p><strong>No Online Deployment</strong> – The model runs locally, making it inaccessible via web or mobile apps</p></li>
                          </ul>

                          <div style="text-align: center;">	
                            <h1><a>Code</a></h1>
                          </div>

                          <pre>
                            <code style="color: white;">
  app.py
  import tkinter as tk  # Import the Tkinter library for GUI creation
  from tkinter import messagebox  # Import messagebox for displaying pop-up messages
  import torch  # Import PyTorch for deep learning model usage
  from torchvision import transforms  # Import torchvision transforms for image preprocessing
  from PIL import Image, ImageDraw  # Import PIL for image manipulation
  import numpy as np  # Import NumPy for numerical operations
  import torch.nn as nn  # Import PyTorch's neural network module
  
  # Define the CNN model architecture (same as used during training)
  class ShapeCNN(nn.Module):
      def __init__(self):
          super(ShapeCNN, self).__init__()  # Initialize the parent class (nn.Module)
          self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)  # First convolutional layer (3 input channels for RGB, 32 output channels)
          self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # Second convolutional layer (32 input channels, 64 output channels)
          self.fc1 = nn.Linear(64 * 16 * 16, 128)  # Fully connected layer (input: flattened feature map, output: 128 neurons)
          self.fc2 = nn.Linear(128, 4)  # Output layer (4 classes: Cross, Square, Triangle, "I don't know")
          self.pool = nn.MaxPool2d(2, 2)  # Max pooling layer (reduces feature map size by half)
          self.relu = nn.ReLU()  # Activation function (ReLU)
  
      def forward(self, x):
          x = self.pool(self.relu(self.conv1(x)))  # Apply first convolution, ReLU activation, then max pooling
          x = self.pool(self.relu(self.conv2(x)))  # Apply second convolution, ReLU activation, then max pooling
          x = x.view(x.size(0), -1)  # Flatten the tensor for fully connected layers
          x = self.relu(self.fc1(x))  # Apply first fully connected layer with ReLU activation
          return self.fc2(x)  # Output layer (no activation, as softmax will be used later if needed)
  
  # Load the trained model weights
  model = ShapeCNN()  # Initialize the model
  model.load_state_dict(torch.load("model/shape_cnn.pth"))  # Load pre-trained model weights from file
  model.eval()  # Set the model to evaluation mode (disables dropout and batch normalization during inference)
  
  # Define class labels
  classes = ['Cross', 'Square', 'Triangle', "I don't know"]  # The four possible shape categories
  
  # Define the preprocessing transformations for input images
  transform = transforms.Compose([
      transforms.Resize((64, 64)),  # Resize image to 64x64 pixels (as expected by the model)
      transforms.ToTensor(),  # Convert image to PyTorch tensor format (C, H, W)
      transforms.Normalize((0.5,), (0.5,))  # Normalize pixel values to range [-1, 1] for better model performance
  ])
  
  # Function to predict shape from an image
  def predict_image(image):
      image = transform(image).unsqueeze(0)  # Apply transformations and add batch dimension
      output = model(image)  # Perform forward pass through the model
      _, predicted = torch.max(output, 1)  # Get index of the class with highest probability
      return classes[predicted.item()]  # Return the corresponding class label
  
  # Tkinter-based drawing application
  class DrawingApp:
      def __init__(self, root):
          self.root = root  # Store root Tkinter window
          self.root.title("Shape Predictor")  # Set window title
  
          self.canvas = tk.Canvas(self.root, width=256, height=256, bg="white")  # Create a drawing canvas
          self.canvas.pack()  # Add canvas to the GUI
  
          self.image = Image.new("RGB", (256, 256), "white")  # Create a blank white image (PIL format)
          self.draw = ImageDraw.Draw(self.image)  # Create a drawing object to modify the image
  
          self.canvas.bind("<B1-Motion>", self.paint)  # Bind mouse movement (while holding left-click) to the paint function
          
          self.clear_button = tk.Button(self.root, text="Clear", command=self.clear_canvas)  # Create a button to clear the canvas
          self.clear_button.pack()  # Add the button to the GUI
          
          self.predict_button = tk.Button(self.root, text="Predict Shape", command=self.predict)  # Create a button to make predictions
          self.predict_button.pack()  # Add the button to the GUI
  
      def paint(self, event):
          x1, y1 = (event.x - 1), (event.y - 1)  # Get mouse coordinates (slightly offset to create a small stroke)
          x2, y2 = (event.x + 1), (event.y + 1)  # Define stroke size
          self.canvas.create_oval(x1, y1, x2, y2, width=5, fill="black", outline="black")  # Draw small oval (simulating brush stroke)
          self.draw.line([x1, y1, x2, y2], fill="black", width=5)  # Draw a line on the PIL image for model input
  
      def clear_canvas(self):
          self.canvas.delete("all")  # Clear the canvas UI
          self.image = Image.new("RGB", (256, 256), "white")  # Reset the image to a blank white canvas
          self.draw = ImageDraw.Draw(self.image)  # Create a new drawing object
  
      def predict(self):
          image_resized = self.image.resize((64, 64))  # Resize image to 64x64 for model compatibility
          prediction = predict_image(image_resized)  # Get predicted shape class
          messagebox.showinfo("Prediction", f"Predicted Shape: {prediction}")  # Display prediction result in a messagebox
  
  # Initialize and run the Tkinter application
  if __name__ == "__main__":
      root = tk.Tk()  # Create the main Tkinter window
      app = DrawingApp(root)  # Initialize the DrawingApp class
      root.mainloop()  # Run the Tkinter event loop (keeps GUI running)
  
  train.py
  import torch  # Import PyTorch for deep learning
  import torch.nn as nn  # Import PyTorch's neural network module
  import torch.optim as optim  # Import optimization functions (Adam, SGD, etc.)
  from torchvision import datasets, transforms  # Import datasets and transformations for image preprocessing
  from torch.utils.data import DataLoader  # Import DataLoader for batch processing
  
  # Define CNN Model
  class ShapeCNN(nn.Module):
      def __init__(self):
          super(ShapeCNN, self).__init__()  # Initialize the parent class (nn.Module)
          self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)  # First convolutional layer (RGB input, 32 output channels)
          self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # Second convolutional layer (32 input channels, 64 output channels)
          self.fc1 = nn.Linear(64 * 16 * 16, 128)  # Fully connected layer (input: flattened feature map, output: 128 neurons)
          self.fc2 = nn.Linear(128, 4)  # Output layer (4 classes: Cross, Square, Triangle, "I don't know")
          self.pool = nn.MaxPool2d(2, 2)  # Max pooling layer (reduces feature map size by half)
          self.relu = nn.ReLU()  # Activation function (ReLU)
  
      def forward(self, x):
          x = self.pool(self.relu(self.conv1(x)))  # Apply first convolution, ReLU activation, then max pooling
          x = self.pool(self.relu(self.conv2(x)))  # Apply second convolution, ReLU activation, then max pooling
          x = x.view(x.size(0), -1)  # Flatten the tensor for fully connected layers
          x = self.relu(self.fc1(x))  # Apply first fully connected layer with ReLU activation
          return self.fc2(x)  # Output layer (raw scores for each class)
  
  # Data preprocessing transformations
  transform = transforms.Compose([
      transforms.Resize((64, 64)),  # Resize images to 64x64 pixels
      transforms.ToTensor(),  # Convert images to PyTorch tensors (C, H, W format)
      transforms.Normalize((0.5,), (0.5,))  # Normalize pixel values to range [-1, 1] for better model performance
  ])
  
  # Load dataset from specified directory
  dataset = datasets.ImageFolder(root="dataset", transform=transform)  # Load images and apply transformations
  
  # Create DataLoader for batch processing
  dataloader = DataLoader(dataset, batch_size=32, shuffle=True)  # Load data in batches of 32, shuffle for randomness
  
  # Initialize model, loss function, and optimizer
  device = torch.device("cuda" if torch.cuda.is_available() else "cpu")  # Use GPU if available, else fallback to CPU
  model = ShapeCNN().to(device)  # Move model to selected device
  criterion = nn.CrossEntropyLoss()  # Define loss function (CrossEntropy for multi-class classification)
  optimizer = optim.Adam(model.parameters(), lr=0.001)  # Use Adam optimizer with learning rate 0.001
  
  # Training loop
  num_epochs = 10  # Set number of training epochs
  for epoch in range(num_epochs):  # Loop through epochs
      for images, labels in dataloader:  # Iterate over batches of data
          images, labels = images.to(device), labels.to(device)  # Move images and labels to GPU if available
  
          optimizer.zero_grad()  # Clear previous gradients
          outputs = model(images)  # Forward pass through the model
          loss = criterion(outputs, labels)  # Compute loss between predictions and actual labels
          loss.backward()  # Backpropagate the loss
          optimizer.step()  # Update model parameters
  
      print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}")  # Print loss for each epoch
  
  # Save trained model weights
  torch.save(model.state_dict(), "model/shape_cnn.pth")  # Save model parameters to a file
  print("Model training complete!")  # Indicate completion of training
  
                            </code>
                          </pre>
                          

                        </div>
					</div>

				<!-- Footer -->
        <footer id="footer">
          <div class="inner">
            <section>
              <h2>Email Me </h2>
              <p>
                petermacero19@gmail.com | ptmacero19@gmail.com
              </p>
            </section>
            <section>
              <h2>Follow</h2>
              <ul class="icons">
                <li><a href="https://github.com/Peter-Troy" class="icon brands style2 fa-github"><span class="label">GitHub</span></a></li>
              </ul>
            </section>

            <ul class="copyright">
              <li>&copy; Peter Troy C. Macero & HTML5 UP . All rights reserved</li>
            </ul>
          </div>
        </footer>

			</div>

		<!-- Scripts -->
			<script src="../assets/js/jquery.min.js"></script>
			<script src="../assets/js/browser.min.js"></script>
			<script src="../assets/js/breakpoints.min.js"></script>
			<script src="../assets/js/util.js"></script>
			<script src="../assets/js/main.js"></script>

	</body>
</html>

